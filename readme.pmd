% Algorithm Report 1: Task Scheduling
% Jon Craton

[![Build Status](https://travis-ci.org/jncraton/build-scheduler.svg?branch=master)](https://travis-ci.org/jncraton/build-scheduler)

Scheduling algoritms are important in many areas of Computer Science including CPU design, compiler design[1], and process scheduling. I will explore the task of applying scheduling to optimizing the ordering of dependent production tasks in the game StarCraft: Brood War.

I will try to use CPU architecture metaphors as much as possible throughout this document to try to make as many connections to existing algorithms as possible. Anything that can perform a task will be thought of as an Execution Unit[3]. One unique aspect of scheduling execution unit in the case of Brood War is that our CPU is able to build new execution units on the fly.

We will first apply some traditional algorithms to handle the typical case where the number and type of execution units are fixed.

First, we need to define some units:

```python
from collections import namedtuple

Unit = namedtuple('ExecutionUnit', ['name','executed_on','min','gas','supply','time','requires'])

Nexus = Unit('Nexus','Probe',400,0,-10,75,tuple())
Assimilator = Unit('Assimilator','Probe',100,0,0,25,tuple())
Pylon = Unit('Pylon','Probe',100,0,-8,19,tuple())
Gateway = Unit('Gateway','Probe',150,0,0,38,('Pylon',))
CyberneticsCore = Unit('CyberneticsCore','Probe',200,0,0,38,('Gateway',))
Observatory = Unit('Observatory','Probe',50,100,0,19,('RoboticsFacility',))
RoboticsFacility = Unit('RoboticsFacility','Probe',200,200,0,50,('CyberneticsCore',))
CitadelOfAdun = Unit('CitadelOfAdun','Probe',150,100,0,38,('CyberneticsCore',))
TemplarArchives = Unit('TemplarArchives','Probe',150,200,0,38,('CitadelOfAdun',))

Probe = Unit('Probe','Nexus',50,0,1,13,tuple())
Zealot = Unit('Zealot','Gateway',100,0,2,25,('Gateway',))
Dragoon = Unit('Dragoon','Gateway',125,50,2,32,('CyberneticsCore',))
DarkTemplar = Unit('DarkTemplar','Gateway',125,100,2,32,('TemplarArchives',))
Observer = Unit('Observer','RoboticsFacility',25,75,1,25,('Observatory',))

units = locals()
```

We also need a little math to calculate income rate based on the current units and structures we possess:

```python
def mining_rate(bases, assimilators, workers):
  """ Returns minerals/sec for a given number of bases, workers, and assimilators 

  https://liquipedia.net/starcraft/Mining

  Check that one base mineral rates scale properly:

  >>> mining_rate(1, 0, 9)
  (9.75, 0.0)
  >>> mining_rate(1, 0, 18)
  (18.0, 0.0)
  >>> mining_rate(1, 0, 27)
  (26.25, 0.0)
  >>> mining_rate(1, 0, 50)
  (26.25, 0.0)

  Check gas rates:

  >>> mining_rate(1, 1, 3)
  (0.0, 5.15)
  >>> mining_rate(1, 2, 6)
  (0.0, 10.3)

  Make sure we don't have any crosstalk between gas and mineral rates:

  >>> mining_rate(1, 1, 12)
  (9.75, 5.15)
  >>> mining_rate(1, 1, 21)
  (18.0, 5.15)
  >>> mining_rate(1, 1, 30)
  (26.25, 5.15)
  >>> mining_rate(1, 1, 50)
  (26.25, 5.15)
  """
  
  min_workers = workers - (assimilators * 3)

  min_workers_per_base = min_workers / bases
  min_per_base = min(min_workers_per_base, 9) * 65/60
  if min_workers_per_base > 9:
    min_per_base += min(min_workers_per_base - 9, 18) * 55/60
      
  return (min_per_base * bases, assimilators * (309 / 60))
```

We'll create a class to wrap our execution units in to track what they are running and how long it will take to finish the work:

```python
def in_production(eus, unit):
  return [e for e in eus if e.running and e.running==unit]

def finished(eus, unit):
  return [e for e in eus if e.unit==unit]

def queued(tasks, unit):
  return [t for t in tasks if t==unit]

def owned(eus, tasks, unit):
  return finished(eus,unit) or queued(tasks,unit) or in_production(eus, unit)

class ExecutionUnit:
  def __init__(self, unit):
    self.unit = unit
    self.idle_at = 0
    self.running = None

  def complete(self):
    completed = self.running
    self.running = None
    self.idle_at = 0
  
    return completed

  def run(self, task, res, time):
    self.running = task
    self.idle_at = task.time + time

    res[0] -= task.min
    res[1] -= task.gas
    if task.supply > 0: # Otherwise we adjust supply on completion
      res[2] -= task.supply

  def can_run(self, eus, task, res):
    if task.min > res[0] or task.gas > res[1] or task.supply > res[2]: return False

    for r in task.requires:
      if not finished(eus, units[r]): return False
  
    return not self.running and (task.executed_on == None or self.unit.name==task.executed_on)
```

Now let's add an `execute` function to schedule a set of tasks. This function takes a list of execution units, a list of tasks to complete, and a scheduler function to decide what to run.

```python
def execute(tasks, scheduler, units=[Nexus] + [Probe] * 4, debug=False):
  """
  Executes a set of tasks using a supplied scheduler
  
  >>> execute([Pylon, Gateway], lambda *x: None)
  85
  >>> execute([Probe] * 4 + [Pylon, Gateway, Zealot], lambda *x: None)
  127
  >>> execute([Probe] * 4 + [Pylon, Gateway, Zealot, Nexus, Zealot], lambda *x: None)
  196
  """

  time = -1
  res = [50,0,6]

  eus = [ExecutionUnit(unit) for unit in units]

  def message(msg):
    if debug:
      print('%ds (%d minerals, %d gas, %d supply): %s' % (time, res[0], res[1], res[2], msg))

  for time in range(0,600):
    for eu in eus:
      if eu.running and eu.idle_at <= time:
        message("Completed %s." % eu.running.name)
        if eu.running.supply < 0:
          res[2] -= eu.running.supply
        eus.append(ExecutionUnit(eu.complete()))

    scheduler(eus, tasks, time, res)

    # Begin running the next task if possible
    if tasks:
      for eu in eus:
        if eu.can_run(eus,tasks[0], res):
          message("Started %s" % tasks[0].name)
          eu.run(tasks[0], res, time)
          tasks.pop(0)
          break

    if not [t for t in tasks if t not in [Probe,Pylon]] and not [idle for idle in eus if not idle.running in [None,Probe,Pylon]]: break

    peons = len([t for t in eus if t.unit == Probe])
    bases = len([t for t in eus if t.unit == Nexus])
    gases = len([t for t in eus if t.unit == Assimilator])
    
    res[0] += mining_rate(bases, gases, peons)[0]
    res[1] += mining_rate(bases, gases, peons)[1]

  if debug:
    print("Total makespan: %ds" % time)
  else:
    return time
```

FIFO (In-order execution)
=========================

One of the simplest scheduling algorithms that we can implement is a simple FIFO system:

```python
def fifo(eus, tasks, time, res):
  """
  Assign tasks to execution units in the order they were supplied.

  This is a noop.
  """

  return

TASKS = [Probe] * 4 + [Pylon] + [Probe] * 4 + [Gateway, Zealot, Zealot]

execute(TASKS[:], fifo, debug=True)
```

Reordering (out-of-order execution)
===================================

We'll now implement a simple algorithm to allow future operations to be scheduled if the next operation is blocked. The CPU metaphor is not perfect here, but this borrows the concept of dependency handling and a reservation station from Tomasulo's algorithm. [4][9]

This algorithm is still trivial in terms of both complexity (O(n)) and correctness (everything still runs), so I'll skip formal validation.

```python
def reorder(eus, tasks, time, res):
  """
  Reorders upcoming tasks if the next task is not runnable. This implements the first step of a selection sort to move the first task that can be run to the front of the task queue.

  The algorithm used here is to simply put the first runnable task as the start of the task queue or do nothing
  """

  for (i, task) in enumerate(tasks):
    for eu in eus:
      if eu.can_run(eus,task, res):
        tasks.insert(0, tasks.pop(i))
        return

execute(TASKS[:], reorder, debug=True)
```

We were able to remove 23s of stalling on this simple task by simply using reordering.

Reordering with automated minerals
==================================

In RTS games, a certain economic size (worker count, base count, etc) is typically a means to an end rather than a goal in itself. For this reason, I have created a scheduler that expects to not be told when to build workers or bases and instead automatically injects these as needed.

For this simple implementation, the scheduler simply builds a worker if it is able to do so and commands fewer than 30 of them.

```python
def automin(eus, tasks, time, res):
  for eu in eus:
    if eu.can_run(eus,Probe, res):
      tasks.insert(0, Probe)
      return True

def reorder_automin(eus, tasks, time, res):
  reorder(eus, tasks, time, res)
  automin(eus, tasks, time, res)

execute([Pylon, Gateway, Zealot, Zealot], reorder_automin, debug=True)
```

Gas management
==============

Brood War has a secondary resource called Vespene Gas (typically just gas) that can be obtained some point after the start of the game, but not immediately. Gas timing is a very important part of build order design, and it is thus far not handle by our simple algorithm.

We will update our scheduler to build a gas mining facility (Assimilator) once it is blocked by a unit that requires gas and has none.

```python
def autogas(eus, tasks, time, res):
  if not tasks: return
  
  if tasks[0].gas > 0 and not owned(eus, tasks, Assimilator):
    for eu in eus:
      if eu.can_run(eus,Assimilator, res):
        tasks.insert(0, Assimilator)
        return True

def reorder_autogas(eus, tasks, time, res):
  reorder(eus, tasks, time, res)
  if autogas(eus, tasks, time, res): return
  if automin(eus, tasks, time, res): return

execute([Pylon, Gateway, Zealot, Zealot, Pylon, CyberneticsCore, Dragoon], reorder_autogas, debug=True)
```

This handles ensuring that we don't get blocked on units that require gas, but it is a very weak planning method.

Supply management
=================

Each unit created in Brood War borrows a fixed amount of "supply" from the players total supply. Supply is created by creating Pylons. We can automatically manage supply in the same way as we just did for gas.

```python
def autosupply(eus, tasks, time, res):
  if not tasks: return

  if tasks[0].supply > res[2] and not in_production(eus, Pylon):
    for eu in eus:
      if eu.can_run(eus, Pylon, res):
        tasks.insert(0, Pylon)
        return True

def reorder_autosupply(eus, tasks, time, res):
  reorder(eus, tasks, time, res)
  autosupply(eus, tasks, time, res)
  
  if reorder_autogas(eus, tasks, time, res):
    return True

execute([Pylon, Gateway, Zealot, Zealot, CyberneticsCore, Dragoon], reorder_autosupply, debug=True)
```

Now we should never be supply blocked. We can also see that this algorithm completes the requested tasks in the same amount of time as the above, but has a stronger economic position.

Directed Acyclic Graph
======================

Let's consider a more complex production problem that includes multiple branches and explore how to optimize it. Let's try to build an Observer and a Dark Templar as quickly as possible.

```python
tasks = [Pylon, Gateway, CyberneticsCore, 
         RoboticsFacility, Observatory, Observer, 
         CitadelOfAdun, TemplarArchives, DarkTemplar
        ]

execute(tasks[:], reorder_autosupply, debug=True)
```

We need to add better planning to handle complicated dependencies. The first step to handling dependencies in a sensible way is to convert our operations into a directed acyclic graphs (DAG).

```python
import math
import networkx as nx
import matplotlib.pyplot as plt

class Node:
  def __init__(self, task):
    self.task = task

  def __str__(self):
    return self.task.name

def get_dag(tasks):
  dag = nx.DiGraph()

  for task in set(tasks):
    dag.add_node(Node(task))

  for n in dag.nodes(data=True):
    n[1]['count'] = len([t for t in tasks if t==n[0].task])
  
  for n1 in dag.nodes:
    for n2 in dag.nodes:
      weight=n2.task.time
      
      if n2.task.executed_on == n1.task.name:
        weight = n2.task.time * math.ceil(dag.node[n2]['count'] / dag.node[n1]['count'])
        dag.add_edge(n1,n2,weight=weight)
        
      for r in n2.task.requires:
        if r == n1.task.name:
          dag.add_edge(n1,n2,weight=weight)

  return dag

def draw_dag(dag):
  pos=nx.spectral_layout(dag)
  plt.figure(1,figsize=(6,6)) 
  nx.draw(dag,pos, with_labels=True, node_size=60,font_size=12)
  labels = nx.get_edge_attributes(dag,'weight')
  nx.draw_networkx_edge_labels(dag,pos,edge_labels=labels, font_size=12)

draw_dag(get_dag(tasks))
```

Topological Sorting and Kahn's Algorithm
----------------------------------------

Next, we need to process our DAG into a list that is sorted topologically. [6]

We'll simply apply Kahn's algorithm to do the sorting[10]. Here's the psuedocode from Wikipedia [6]:

    L ← Empty list that will contain the sorted elements
    S ← Set of all nodes with no incoming edge
    while S is non-empty do
        remove a node n from S
        add n to tail of L
        for each node m with an edge e from n to m do
            remove edge e from the graph
            if m has no other incoming edges then
                insert m into S
    if graph has edges then
        return error (graph has at least one cycle)
    else 
        return L (a topologically sorted order)

Now we simply sort our DAG topologically:

```python3
[str(n) for n in nx.topological_sort(get_dag(tasks))]
```

Critical Path
-------------

Our scheduling system up to this point does not include any advanced planning and simply tries to grab the first available piece of work. What we would like to do is find the critical path[13] through our DAG and begin working on it first. Generally, we need to solve the longest path problem[14] for our DAG.

> The critical path method for scheduling a set of activities involves the construction of a directed acyclic graph in which the vertices represent project milestones and the edges represent activities that must be performed after one milestone and before another; each edge is weighted by an estimate of the amount of time the corresponding activity will take to complete. In such a graph, the longest path from the first milestone to the last one is the critical path, which describes the total time for completing the project. [14]

The longest path problem for a general graph is NP-hard, but the variant needed to DAGs is not particularly interesting and linear time. Here's the basic idea:

> 1. Find a topological ordering of the given DAG.
> 2. For each vertex v of the DAG, in the topological ordering, compute the length of the longest path ending at v by looking at its incoming neighbors and adding one to the maximum length recorded for those neighbors. If v has no incoming neighbors, set the length of the longest path ending at v to zero. In either case, record this number so that later steps of the algorithm can access it.
> 3. Once this has been done, the longest path in the whole DAG may be obtained by starting at the vertex v with the largest recorded value, then repeatedly stepping backwards to its incoming neighbor with the largest recorded value, and reversing the sequence of vertices found in this way. [14]

Here's the result of applying this to our DAG:

```python
[str(n) for n in nx.dag_longest_path(get_dag(tasks))]
```

Let's now build a scheduler that uses the critical path to decide what to run next.

```python
def critical_path(eus, tasks, time, res):
  if not tasks: return

  new_start = nx.dag_longest_path(get_dag(tasks))[0]
  tasks.remove(new_start.task)
  tasks.insert(0, new_start.task)

  if autosupply(eus, tasks, time, res): return
  if automin(eus, tasks, time, res): return
  if autogas(eus, tasks, time, res): return

execute(tasks[:], critical_path, debug=True)
```

Note that the scheduler must recalculate the critical path on each run as the first element of the critical path may sometimes not be the second element from the previous run. This is due to the fact that there may be multiple paralell that need to be executed as such to optimize time efficiency.

Complexity and Correctness
--------------------------

This scheduler ends up with O(n²) complexity with the number of steps in the build. It requires linear time to determine the critcal path, but this path must be calculated again for every step, so we end up with O(n²) time.

This algorithm is obvious correct in that it completes the task at hand, but it is still not optimal.

Investment
==========

The next thing that we need to add to our scheduler is the concept of investment. Consider the following task:

```python
zealots = [Pylon,Gateway] + [Zealot]*12
execute(zealots[:], critical_path, debug=True)
```

And the simple DAG:

```python
draw_dag(get_dag(zealots))
```

This algorithm misses a key issue. While the gateway allows zealots to be built, it also creates a bottleneck. Right now, zealots are built individually over a long period of time. In Brood War, we have the option to invest in any number of gateways, so let's update our algorithm to handle explore that possibility.

Let's try adding some tests to see if we can improve our longest path. Here's the current longest path:

```python
nx.dag_longest_path_length(get_dag(zealots))
```

And now with an extra gateway:

```python
two_gates = get_dag(zealots + [Gateway])
draw_dag(two_gates)
nx.dag_longest_path_length(two_gates)
```

This is almost twice as fast. Let's see if we can create an algorithm to automatically parallelize these hot paths in a scheduler.

```python
def parallelize(eus, tasks, time, res):
  if not tasks: return

  final = nx.dag_longest_path(get_dag(tasks))[-1]
  bottleneck = final.task.executed_on

  completed = [e.unit for e in eus[5:] if e.unit.executed_on == 'Probe'] # Exclude starting units

  current = nx.dag_longest_path_length(get_dag(completed + tasks))
  new = nx.dag_longest_path_length(get_dag(completed + tasks + [units[bottleneck]]))

  if new < current:
    for eu in eus:
      if eu.can_run(eus, units[bottleneck], res):
        tasks.insert(0, units[bottleneck])
        return True

  critical_path(eus, tasks, time, res)
  
execute(zealots[:], parallelize, debug=True)
```

Hotspot removal
===============

There are several ways to attempt this. The first I'll try to implement is the detection and removal of hotspots in 

References
==========

1. http://www.cl.cam.ac.uk/teaching/2005/OptComp/slides/lecture14.pdf
2. https://en.wikipedia.org/wiki/Scheduling_(computing)
3. https://en.wikipedia.org/wiki/Execution_unit
4. https://www.cc.gatech.edu/fac/milos/Teaching/CS6290F07/4_Tomasulo.pdf
5. https://www.kth.se/social/upload/62/microprocessor_design.pdf
6. https://en.wikipedia.org/wiki/Topological_sorting
7. https://en.wikipedia.org/wiki/Coffman%E2%80%93Graham_algorithm
8. https://en.wikipedia.org/wiki/Job_shop_scheduling
9. https://en.wikipedia.org/wiki/Tomasulo_algorithm
10. Kahn, Arthur B. (1962), "Topological sorting of large networks", Communications of the ACM, 5 (11): 558–562, doi:10.1145/368996.369025.
11. http://www.cs.mun.ca/~dchurchill/pdf/aiide11-bo.pdf
12. http://richoux.fr/publications/ecgg15_chapter-rts_ai.pdf
13. https://en.wikipedia.org/wiki/Critical_path_method
14. https://en.wikipedia.org/wiki/Longest_path_problem
